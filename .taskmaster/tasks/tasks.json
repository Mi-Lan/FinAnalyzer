{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Setup Project Repository & CI/CD Pipeline",
        "description": "Initialize monorepo structure and configure CI/CD for automated testing and deployment.",
        "details": "Use pnpm workspaces for monorepo management. Set up GitHub Actions for CI/CD with linting, testing, and deployment workflows. Configure Docker for local development and deployment. Recommended: pnpm v8, GitHub Actions, Docker v24.\n<info added on 2025-06-20T11:59:51.241Z>\n## Monorepo Best Practices (2024-2025)\n\n### Monorepo Structure\n- Organize into `apps/` for deployable services and `packages/` for shared libraries\n- Configure `pnpm-workspace.yaml` at root to define package directories\n- Use pnpm v8+ with workspace protocol references (workspace:*) for internal dependencies\n\n### Performance Optimizations\n- Implement isolated builds with pnpm filtering or Turborepo/Nx for large repos\n- Structure Dockerfiles to maximize layer caching with multi-stage builds\n- Use parallelization in GitHub Actions with matrix builds\n\n### CI/CD Pipeline\n- Set up separate jobs for linting, testing, building, and deployment\n- Cache pnpm store and node_modules with proper hash-based keys\n- Use `pnpm install --frozen-lockfile` for reproducible builds\n\n### Docker Containerization\n- Create service-specific Dockerfiles that only include relevant packages\n- Handle pnpm symlinks properly by building standalone artifacts\n- Use minimal base images (node:20-alpine) and run as non-root\n\n### Security Considerations\n- Pin dependencies with lockfiles and scan for vulnerabilities\n- Use GitHub Secrets for CI/CD and proper secrets management\n- Implement branch protection for workflow and deployment changes\n\n### Recommended Tooling\n- Consider Turborepo or Nx for advanced task orchestration in larger repos\n- Use Trivy/Snyk for container and dependency scanning\n- Enable Docker BuildKit for faster, more secure builds\n</info added on 2025-06-20T11:59:51.241Z>",
        "testStrategy": "Verify repository structure, CI/CD pipeline triggers, and Docker build success.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Initialize Monorepo Structure",
            "description": "Set up the base directory structure for the monorepo, including root configuration files and subdirectories for apps and packages.",
            "dependencies": [],
            "details": "Create the root directory, initialize it with pnpm, and add a pnpm-workspace.yaml file specifying workspace patterns (e.g., 'apps/*', 'packages/*'). Create the 'apps' and 'packages' directories.\n<info added on 2025-06-20T12:53:47.215Z>\nCreated the root directory structure for the monorepo. Initialized the project with pnpm and added a pnpm-workspace.yaml file that defines the workspace patterns to include 'apps/*' and 'packages/*'. Successfully created the 'apps' and 'packages' directories as specified in the workspace configuration.\n</info added on 2025-06-20T12:53:47.215Z>",
            "status": "done"
          },
          {
            "id": 2,
            "title": "Configure PNPM Workspaces",
            "description": "Configure pnpm to manage dependencies and scripts across all workspace packages.",
            "dependencies": [
              1
            ],
            "details": "Ensure pnpm is enabled and properly installed. Set up the pnpm-workspace.yaml file to include all relevant packages and apps. Initialize package.json files as needed in each workspace.\n<info added on 2025-06-20T12:54:16.999Z>\npnpm has been successfully enabled for the project and the `pnpm-workspace.yaml` file has been properly configured to include all relevant packages and apps. Note that the initialization of individual `package.json` files within workspaces will not be handled in this subtask, but will instead be addressed in the specific tasks dedicated to creating those applications and packages.\n</info added on 2025-06-20T12:54:16.999Z>",
            "status": "done"
          },
          {
            "id": 3,
            "title": "Set Up Development Tooling",
            "description": "Install and configure essential development tools such as ESLint, Prettier, and any pre-commit hooks for code quality and consistency.",
            "dependencies": [
              2
            ],
            "details": "Add ESLint and Prettier as dev dependencies at the root. Create configuration files (.eslintrc.json, .prettierrc.json, etc.) and set up ignore files. Optionally, configure Husky and lint-staged for pre-commit checks.\n<info added on 2025-06-20T13:08:23.445Z>\nConfigured ESLint, Prettier, Husky, and lint-staged for the project. Created `.eslintrc.json`, `.prettierrc.json`, `.prettierignore`, and `.lintstagedrc.json`. Initialized Husky and updated the pre-commit hook. Note: The installation of npm packages failed due to a persistent environment issue, but all configuration is complete.\n</info added on 2025-06-20T13:08:23.445Z>",
            "status": "done"
          },
          {
            "id": 4,
            "title": "Configure GitHub Actions Workflows",
            "description": "Set up GitHub Actions workflows for linting, testing, and deployment automation.",
            "dependencies": [
              3
            ],
            "details": "Create workflow YAML files in .github/workflows for linting, running tests, and deployment. Ensure workflows use pnpm for installing dependencies and running scripts across workspaces.\n<info added on 2025-06-20T13:09:47.564Z>\nCreated a GitHub Actions workflow file at `.github/workflows/ci.yml` that triggers on push and pull requests to the main branch. The CI pipeline performs the following steps:\n1. Installs dependencies using pnpm\n2. Runs linting checks\n3. Executes test suites\n4. Tests compatibility across Node.js versions 18 and 20\n\nThe workflow ensures code quality and functionality are maintained with each contribution to the repository.\n</info added on 2025-06-20T13:09:47.564Z>",
            "status": "done"
          },
          {
            "id": 5,
            "title": "Set Up Docker for Local and Production Environments",
            "description": "Create Dockerfiles and docker-compose configurations to support both local development and production deployments.",
            "dependencies": [
              4
            ],
            "details": "Write Dockerfiles for each app/service as needed. Create a docker-compose.yml for local orchestration. Ensure production Dockerfiles are optimized for deployment (multi-stage builds, minimal images).\n<info added on 2025-06-20T13:10:51.171Z>\nCreated a multi-stage `Dockerfile` to serve as a base template for all future services, implementing best practices for optimized production images. Set up a `docker-compose.yml` configuration that includes a `postgres` service to support local development environments. Added a `.dockerignore` file to exclude unnecessary files from the build context, improving build performance and reducing image size.\n</info added on 2025-06-20T13:10:51.171Z>",
            "status": "done"
          },
          {
            "id": 6,
            "title": "Initial CI/CD Verification",
            "description": "Run and verify the complete CI/CD pipeline, ensuring all workflows, linting, testing, and Docker builds function as expected.",
            "dependencies": [
              5
            ],
            "details": "Trigger the GitHub Actions workflows manually or via a test commit. Confirm that linting, tests, and Docker builds pass successfully and that deployment steps (if any) execute without errors.\n<info added on 2025-06-20T13:11:17.951Z>\nAll configuration for CI/CD is complete. To verify:\n1. Commit current changes\n2. Push to a feature branch\n3. Open a pull request against main branch\n4. Observe GitHub Actions workflow triggering automatically\n5. Confirm all checks pass successfully\n\nWaiting for user to perform these manual verification steps before marking this subtask as complete.\n</info added on 2025-06-20T13:11:17.951Z>",
            "status": "done"
          }
        ]
      },
      {
        "id": 2,
        "title": "Design and Deploy PostgreSQL Schema",
        "description": "Define and deploy the core database schema with JSONB fields as specified.",
        "details": "Use SQLAlchemy or Prisma for schema definition. Deploy to Supabase or AWS RDS. Implement all core entities: Company, FinancialData, AnalysisTemplate, AnalysisResult, BulkAnalysisJob. Recommended: PostgreSQL v15, SQLAlchemy v2.0, Prisma v5.",
        "testStrategy": "Validate schema creation, table relationships, and JSONB field support.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Design Relational Schema with JSONB Fields",
            "description": "Define the database schema, including tables, relationships, and JSONB fields to accommodate flexible data structures as required by the application.",
            "dependencies": [],
            "details": "Identify entities, their attributes, and relationships. Specify which fields require JSONB for semi-structured data. Document schema decisions for later reference.\n<info added on 2025-06-20T19:21:02.749Z>\nCreated the initial `schema.prisma` file in `packages/database/prisma/`. The schema defines the core models: `Company`, `FinancialData`, `AnalysisTemplate`, `AnalysisResult`, and `BulkAnalysisJob`. Relationships and `Json` fields for flexible data storage have been included as per the design.\n</info added on 2025-06-20T19:21:02.749Z>",
            "status": "done"
          },
          {
            "id": 2,
            "title": "Select ORM Tool: SQLAlchemy vs Prisma",
            "description": "Evaluate and choose between SQLAlchemy and Prisma based on project requirements, language ecosystem, type safety, developer experience, and operational needs.",
            "dependencies": [
              1
            ],
            "details": "Compare features such as type safety, schema synchronization, language support, and ease of use. Document the rationale for the selected tool.\n<info added on 2025-06-20T19:20:15.512Z>\nDecision: Prisma has been selected as the ORM for this project.\n\nRationale: Prisma is the ideal choice for this monorepo environment, which includes a Python/FastAPI backend and a Next.js/TypeScript frontend. Its schema-first approach provides a single source of truth, generating types for both the backend and frontend. This ensures type safety across the stack, reduces the risk of schema drift between services, and significantly improves developer experience by enabling autocompletion and compile-time checks. While SQLAlchemy offers deep, powerful features for Python, Prisma's seamless cross-language integration and modern developer experience are more aligned with the project's needs.\n</info added on 2025-06-20T19:20:15.512Z>",
            "status": "done"
          },
          {
            "id": 3,
            "title": "Model Entities Using Chosen ORM",
            "description": "Implement the entity models and relationships in code using the selected ORM tool, ensuring correct mapping of JSONB fields and relational constraints.",
            "dependencies": [
              2
            ],
            "details": "Translate the schema design into ORM models (e.g., SQLAlchemy classes or Prisma schema). Validate that JSONB fields are correctly represented and relationships are enforced.",
            "status": "done"
          },
          {
            "id": 4,
            "title": "Deploy Schema to Managed Cloud Database",
            "description": "Provision a managed cloud database (e.g., AWS RDS, Azure Database, or similar), and deploy the schema using migration tools provided by the selected ORM.",
            "dependencies": [
              3
            ],
            "details": "Set up the cloud database instance, configure access, and run migrations or schema deployment commands to create tables and relationships as defined.",
            "status": "done"
          },
          {
            "id": 5,
            "title": "Implement and Test Schema Validation",
            "description": "Develop and execute validation routines to ensure the deployed schema matches the intended design, including constraints, data types, and JSONB field structure.",
            "dependencies": [
              4
            ],
            "details": "Use ORM validation features and/or custom scripts to verify schema correctness. Test CRUD operations, relationship integrity, and JSONB data handling.",
            "status": "done"
          }
        ]
      },
      {
        "id": 3,
        "title": "Implement Data Ingestion Adapter for FMP API",
        "description": "Build a robust, extensible adapter to fetch financial data from Financial Modeling Prep (FMP) with a modular design that can accommodate additional data sources in the future.",
        "status": "done",
        "dependencies": [
          1
        ],
        "priority": "high",
        "details": "Use Python with httpx or aiohttp for async requests. Implement rate limiting (300 calls/min). Cache responses in Redis. Design a plugin architecture to support multiple data providers. Reference FMP API documentation at https://site.financialmodelingprep.com/developer/docs/. Recommended: httpx v0.27, aiohttp v3.9, Redis v7.",
        "testStrategy": "Test API calls, rate limiting, and data parsing for IS/BS/CF/10-K/10-Q. Include tests for the plugin architecture and extension points.",
        "subtasks": [
          {
            "id": 1,
            "title": "FMP API Integration Setup",
            "description": "Register for an FMP account, obtain an API key, and configure secure storage and retrieval of the key for use in the application.",
            "dependencies": [],
            "details": "Follow FMP documentation to register and generate an API key. Store the key in environment variables (.env file for development, secure secrets manager for production). Create a configuration system that can handle multiple provider credentials.\n<info added on 2025-06-19T15:15:20.782Z>\n**API Key Storage Best Practices:**\n- Development: Store in `.env` file as `FMP_API_KEY=your_key_here`\n- Production: Use managed secrets (AWS Secrets Manager, Azure Key Vault, etc.)\n- Never commit API keys to version control\n- Add `.env` to `.gitignore`\n\n**FMP API Key Format:**\n- API key must be appended to requests as `?apikey=YOUR_API_KEY` or `&apikey=YOUR_API_KEY` if other params exist\n- Reference: https://site.financialmodelingprep.com/developer/docs/stable\n\n**Provider Configuration Structure:**\n```python\n# Example configuration for multiple providers\nPROVIDERS = {\n    'fmp': {\n        'api_key': os.getenv('FMP_API_KEY'),\n        'base_url': 'https://financialmodelingprep.com/stable',\n        'rate_limit': 300,  # calls per minute\n        'timeout': 30\n    },\n    # Future providers can be added here\n}\n```\n</info added on 2025-06-19T15:15:20.782Z>",
            "status": "done"
          },
          {
            "id": 2,
            "title": "Async HTTP Client Implementation",
            "description": "Implement an asynchronous HTTP client to interact with FMP API endpoints, supporting concurrent requests and proper authentication.",
            "dependencies": [
              1
            ],
            "details": "Use an async HTTP library (e.g., httpx or aiohttp for Python) to build a reusable client that attaches the API key to each request and supports async/await patterns. Design the client with interfaces that can be implemented for different data providers.",
            "status": "done"
          },
          {
            "id": 3,
            "title": "Rate Limiting System",
            "description": "Design and implement a rate limiting mechanism to ensure API requests do not exceed FMP's allowed thresholds.",
            "dependencies": [
              2
            ],
            "details": "Implement a token bucket or leaky bucket algorithm, or use a third-party library, to throttle outgoing requests per FMP's documented rate limits. Integrate with the async client to queue or delay requests as needed. Make the rate limiting configurable per data provider.",
            "status": "done"
          },
          {
            "id": 4,
            "title": "Redis Caching Layer",
            "description": "Integrate Redis as a caching layer to store and retrieve API responses, reducing redundant requests and improving performance.",
            "dependencies": [
              2,
              3
            ],
            "details": "Set up Redis connection pooling and implement cache read/write logic keyed by request parameters and endpoint. Configure cache expiration policies based on data volatility. Design the caching system to work with any data provider.",
            "status": "done"
          },
          {
            "id": 5,
            "title": "Data Parsing for Financial Statements",
            "description": "Develop robust parsers for different FMP financial statement endpoints: Income Statement (IS), Balance Sheet (BS), Cash Flow (CF), 10-K, and 10-Q.",
            "dependencies": [
              2
            ],
            "details": "For each statement type, define data models and parsing logic to transform raw API responses into structured, validated objects suitable for downstream use. Reference specific FMP API endpoints: /income-statement, /balance-sheet-statement, /cash-flow-statement, /sec_filings.\n<info added on 2025-06-19T15:15:39.288Z>\n**Primary FMP Endpoints to Implement:**\n\n1. **Income Statements:**\n   - Annual: `GET /income-statement?symbol=AAPL&period=annual`\n   - Quarterly: `GET /income-statement?symbol=AAPL&period=quarter`\n\n2. **Balance Sheet:**\n   - Annual: `GET /balance-sheet-statement?symbol=AAPL&period=annual`\n   - Quarterly: `GET /balance-sheet-statement?symbol=AAPL&period=quarter`\n\n3. **Cash Flow:**\n   - Annual: `GET /cash-flow-statement?symbol=AAPL&period=annual`\n   - Quarterly: `GET /cash-flow-statement?symbol=AAPL&period=quarter`\n\n4. **SEC Filings (10-K/10-Q):**\n   - `GET /sec_filings?symbol=AAPL&type=10-K&page=0`\n   - `GET /sec_filings?symbol=AAPL&type=10-Q&page=0`\n\n5. **Bulk Endpoints for Scale:**\n   - `GET /income-statement-bulk?year=2024&period=annual`\n   - `GET /balance-sheet-statement-bulk?year=2024&period=annual`\n   - `GET /cash-flow-statement-bulk?year=2024&period=annual`\n\n**Parser Design Pattern:**\nCreate abstract parser interface that can handle different statement types and be extended for other providers:\n\n```python\nclass FinancialStatementParser(ABC):\n    @abstractmethod\n    def parse_income_statement(self, raw_data: dict) -> IncomeStatement:\n        pass\n    \n    @abstractmethod\n    def parse_balance_sheet(self, raw_data: dict) -> BalanceSheet:\n        pass\n    \n    @abstractmethod\n    def parse_cash_flow(self, raw_data: dict) -> CashFlow:\n        pass\n```\n</info added on 2025-06-19T15:15:39.288Z>",
            "status": "done"
          },
          {
            "id": 6,
            "title": "Error Handling and Monitoring",
            "description": "Implement comprehensive error handling for network, API, and parsing errors, and integrate monitoring/logging for observability.",
            "dependencies": [
              2,
              3,
              4,
              5
            ],
            "details": "Handle HTTP errors, timeouts, rate limit breaches, and data validation failures. Log errors and key metrics to a monitoring system (e.g., Sentry, Prometheus) for alerting and diagnostics. Create provider-agnostic error handling patterns.",
            "status": "done"
          },
          {
            "id": 7,
            "title": "Integration and End-to-End Testing",
            "description": "Develop integration and end-to-end tests covering async client, rate limiting, caching, data parsing, and error handling for all supported endpoints.",
            "dependencies": [
              2,
              3,
              4,
              5,
              6
            ],
            "details": "Write tests that simulate real-world usage, including concurrent requests, cache hits/misses, rate limit scenarios, and error conditions. Use test doubles or sandbox endpoints where possible.",
            "status": "done"
          },
          {
            "id": 8,
            "title": "Plugin Architecture Design",
            "description": "Design and implement a plugin architecture that allows for easy addition of new financial data providers beyond FMP.",
            "dependencies": [
              2,
              3,
              4,
              5
            ],
            "details": "Create abstract base classes or interfaces for data providers, rate limiters, and parsers. Implement a provider registry and discovery mechanism. Document the extension points and provide examples for adding new providers.",
            "status": "done"
          },
          {
            "id": 9,
            "title": "Provider-Specific Configuration System",
            "description": "Develop a configuration system that can handle settings for multiple data providers, including credentials, rate limits, and endpoint URLs.",
            "dependencies": [
              1,
              8
            ],
            "details": "Create a flexible configuration structure that supports different provider requirements. Implement validation for provider-specific settings. Support environment-based configuration switching (dev/test/prod).",
            "status": "done"
          },
          {
            "id": 10,
            "title": "Documentation for Provider Extension",
            "description": "Create comprehensive documentation on how to extend the adapter with new data providers.",
            "dependencies": [
              8,
              9
            ],
            "details": "Document the plugin architecture, required interfaces, configuration format, and provide step-by-step examples of adding a new provider. Include diagrams showing the extension points and component interactions.",
            "status": "done"
          }
        ]
      },
      {
        "id": 4,
        "title": "Scaffold Next.js Frontend with Mock Data",
        "description": "Set up Next.js frontend with Tailwind CSS, shadcn/ui, and mock data for rapid prototyping.",
        "details": "Use Next.js v14, Tailwind CSS v3.4, shadcn/ui v0.7. Create mock data endpoints for dashboard and company views. Recommended: Next.js v14, Tailwind CSS v3.4, shadcn/ui v0.7.",
        "testStrategy": "Verify UI components render with mock data and responsive layout.",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Initialize Next.js 14 Project with TypeScript",
            "description": "Set up a new Next.js 14 project using create-next-app, enable TypeScript, configure ESLint, and establish a scalable project structure following best practices.",
            "dependencies": [],
            "details": "Run the Next.js CLI to scaffold the project, select TypeScript, and organize folders (e.g., app, pages, public, src). Ensure TypeScript is fully integrated and linting is enabled for code quality.\n<info added on 2025-06-21T14:06:27.882Z>\nSuccessfully created Next.js 14 project in apps/web with Next.js 15.3.4 (latest stable), React 19.0.0, TypeScript, and App Router. Project includes Tailwind CSS configuration, ESLint setup, src/ directory structure, and \"@/*\" import alias. The project has been properly integrated into the pnpm monorepo structure, providing a solid foundation for the frontend development.\n</info added on 2025-06-21T14:06:27.882Z>",
            "status": "done"
          },
          {
            "id": 2,
            "title": "Integrate Tailwind CSS and shadcn/ui Components",
            "description": "Install and configure Tailwind CSS for utility-first styling and set up shadcn/ui for reusable, accessible UI components.",
            "dependencies": [
              1
            ],
            "details": "Follow Tailwind CSS installation steps for Next.js, add required configuration files, and verify integration. Install shadcn/ui, import base components, and ensure compatibility with Tailwind.\n<info added on 2025-06-21T14:07:53.816Z>\nSuccessfully integrated Tailwind CSS and shadcn/ui:\n- Tailwind CSS v4 was already configured during Next.js setup\n- shadcn/ui successfully initialized with next-monorepo template\n- Base color set to slate\n- CSS variables configured in globals.css\n- utils.ts file created for className utilities\n- Added essential UI components: button, card, table, badge\n- All dependencies properly linked in the monorepo\n</info added on 2025-06-21T14:07:53.816Z>",
            "status": "done"
          },
          {
            "id": 3,
            "title": "Implement Mock API Endpoints with Comprehensive Financial Data",
            "description": "Create mock API endpoints within the Next.js app to serve sample financial data for dashboards and company analysis views.",
            "dependencies": [
              1
            ],
            "details": "Use Next.js API routes to define endpoints (e.g., /api/companies, /api/financials). Populate with realistic mock data structures for companies, financial metrics, and analysis results.\n<info added on 2025-06-21T14:16:47.785Z>\nSuccessfully implemented mock API endpoints with comprehensive financial data:\n- Created TypeScript types matching FMP Pydantic models and Prisma schema\n- Implemented mock data generators for FMP financial statements (Income Statement, Balance Sheet, Cash Flow)\n- Created API endpoints:\n  - GET /api/companies - List all companies\n  - GET /api/companies/[ticker] - Get company details with financials and analysis\n  - GET /api/analysis/screen - Screen companies with filters\n  - GET/POST /api/analysis/bulk - Bulk analysis job management\n- Mock data includes realistic financial numbers based on company size and sector\n- All data structures match the exact FMP data models from the Python backend\n</info added on 2025-06-21T14:16:47.785Z>",
            "status": "done"
          },
          {
            "id": 4,
            "title": "Prototype Initial UI: Dashboard and Company Analysis Views",
            "description": "Develop initial UI screens for the financial analysis platform, including a dashboard overview and detailed company analysis pages, using TypeScript, Tailwind, and shadcn/ui components.",
            "dependencies": [
              2,
              3
            ],
            "details": "Build responsive dashboard and company analysis views, consuming mock API data. Ensure TypeScript types are used throughout components and data fetching logic.\n<info added on 2025-06-21T14:26:22.667Z>\nSuccessfully prototyped initial UI with dashboard and company analysis views:\n- Set up TanStack Query for data fetching with providers\n- Created custom hooks for API data fetching (useCompanies, useCompanyDetails, useScreening, useBulkAnalysisJob)\n- Built reusable components:\n  - ScoreCard: Visual display of analysis scores with color-coded metrics\n  - FinancialMetrics: Comprehensive display of income statement, balance sheet, and cash flow data\n- Created main dashboard page showing:\n  - Top 3 performing companies with score cards\n  - All companies table with filtering and navigation\n- Implemented detailed company analysis page with:\n  - Analysis scores and recommendations\n  - Key insights (strengths, weaknesses, opportunities, risks)\n  - Financial metrics display\n- Resolved Tailwind CSS v4 conflicts by downgrading to v3\n- Application is now running successfully on localhost:3000\n</info added on 2025-06-21T14:26:22.667Z>",
            "status": "done"
          }
        ]
      },
      {
        "id": 5,
        "title": "Build FastAPI Gateway for FE/BE Communication",
        "description": "Develop a FastAPI gateway to connect frontend and backend services, implementing specific endpoints required by the Next.js frontend.",
        "status": "done",
        "dependencies": [
          1,
          2
        ],
        "priority": "medium",
        "details": "Use FastAPI v0.109 for API endpoints. Implement basic auth and request validation. Ensure all endpoints match the frontend's API contract requirements. Pydantic models must align with TypeScript interfaces in apps/web/src/types/financial.ts. Recommended: FastAPI v0.109, Pydantic v2.6.",
        "testStrategy": "Test API endpoints with Postman/curl, validate request/response flow. Ensure responses match the expected formats from the frontend contract.",
        "subtasks": [
          {
            "id": 1,
            "title": "FastAPI Project Setup",
            "description": "Initialize a new FastAPI project, set up a virtual environment, and install required dependencies such as FastAPI and Uvicorn.",
            "status": "done",
            "dependencies": [],
            "details": "Create a project directory, set up a Python virtual environment, and install FastAPI and Uvicorn using a requirements.txt file. Ensure the project structure is ready for further development.",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Endpoint Definition",
            "description": "Define the API endpoints for the gateway according to the frontend contract requirements.",
            "status": "done",
            "dependencies": [
              1
            ],
            "details": "Create a main.py file and implement the required endpoints: GET /api/companies, GET /api/companies/{ticker}, GET /api/analysis/screen, and GET/POST /api/analysis/bulk. Structure endpoints to match frontend expectations.",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Authentication Implementation",
            "description": "Add authentication to the API gateway to secure endpoints.",
            "status": "done",
            "dependencies": [
              2
            ],
            "details": "Implement authentication (e.g., OAuth2, JWT, or API key) using FastAPI's security utilities. Protect all endpoints to require authentication as needed.",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Pydantic Model Implementation",
            "description": "Create Pydantic models that match the TypeScript interfaces in the frontend.",
            "status": "done",
            "dependencies": [
              2
            ],
            "details": "Implement Pydantic models that align with TypeScript interfaces in apps/web/src/types/financial.ts. Include models for FMP financial statements (IncomeStatement, BalanceSheet, CashFlow), Analysis models (AnalysisResult, MetricScores, AnalysisInsights), and Company and FinancialData models.",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Request Validation",
            "description": "Implement request validation for incoming data using the defined Pydantic models.",
            "status": "done",
            "dependencies": [
              3,
              4
            ],
            "details": "Use the Pydantic models in endpoint definitions to ensure data is validated automatically. Implement proper error handling that matches frontend expectations.",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Companies List Endpoint Implementation",
            "description": "Implement the GET /api/companies endpoint to return a list of companies with basic information.",
            "status": "done",
            "dependencies": [
              2,
              4
            ],
            "details": "Create the endpoint that returns company list data in the format expected by the frontend. Include pagination if necessary and ensure response format matches frontend expectations.",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Company Detail Endpoint Implementation",
            "description": "Implement the GET /api/companies/{ticker} endpoint to return detailed company data.",
            "status": "done",
            "dependencies": [
              2,
              4
            ],
            "details": "Create the endpoint that returns detailed company information including financials and analysis for a specific ticker. Ensure the response format matches frontend expectations.",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Analysis Screening Endpoint Implementation",
            "description": "Implement the GET /api/analysis/screen endpoint for filtering companies.",
            "status": "done",
            "dependencies": [
              2,
              4
            ],
            "details": "Create the endpoint that allows screening companies with filters such as minScore, sector, etc. Ensure query parameters are properly validated and the response format matches frontend expectations.",
            "testStrategy": ""
          },
          {
            "id": 9,
            "title": "Bulk Analysis Endpoint Implementation",
            "description": "Implement the GET/POST /api/analysis/bulk endpoints for handling bulk analysis jobs.",
            "status": "done",
            "dependencies": [
              2,
              4
            ],
            "details": "Create endpoints to handle bulk analysis jobs with progress tracking. Implement both GET (status check) and POST (job submission) methods. Ensure response formats match frontend expectations.",
            "testStrategy": ""
          },
          {
            "id": 10,
            "title": "Integration Testing",
            "description": "Write integration tests to verify all endpoint functionality, authentication, and validation.",
            "status": "done",
            "dependencies": [
              5,
              6,
              7,
              8,
              9
            ],
            "details": "Set up a testing framework (e.g., pytest) and write tests that simulate requests to all API endpoints, checking for correct responses, authentication enforcement, and validation errors. Ensure tests verify that responses match the expected formats from the frontend contract.",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 6,
        "title": "Implement Real-Time Data Pull and Storage",
        "description": "Fetch and store IS/BS/CF/10-K/10-Q data from FMP in PostgreSQL.",
        "details": "Extend data ingestion adapter to parse and store data in FinancialData table. Use async processing for efficiency. Recommended: SQLAlchemy v2.0, httpx v0.27.",
        "testStrategy": "Validate data integrity, parsing accuracy, and storage in PostgreSQL.",
        "priority": "high",
        "dependencies": [
          2,
          3
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Extend Adapter for New Data Types",
            "description": "Modify the adapter to support additional data types required for real-time ingestion and storage.",
            "dependencies": [],
            "details": "Analyze current adapter structure and implement support for all necessary data types, ensuring compatibility with backend storage and parsing logic.\n<info added on 2025-06-24T14:53:19.470Z>\nI've completed the adapter extension for new data types and database storage integration. The implementation includes:\n\n1. Database infrastructure:\n   - Added PostgreSQL async support with asyncpg, databases, and sqlalchemy\n   - Created SQLAlchemy models matching the Prisma schema (Company, FinancialData, AnalysisTemplate, AnalysisResult, BulkAnalysisJob)\n   - Implemented DatabaseManager with connection pooling, session management, and CRUD operations\n\n2. Enhanced adapter functionality:\n   - Developed StorageEnabledFMPAdapter extending the base FMPAdapter\n   - Added data preprocessing, organization, and storage capabilities\n   - Implemented period/year extraction and normalization (Q1-Q4, FY)\n   - Created batch operations for comprehensive data fetching\n\n3. Architecture improvements:\n   - Updated factory pattern to support both regular and storage-enabled adapters\n   - Enhanced configuration with DatabaseSettings for PostgreSQL connections\n   - Ensured proper package exports through __init__.py files\n\nThe adapter now operates in two modes:\n- Basic Mode: API-only operations via get_adapter(\"fmp\", enable_storage=False)\n- Storage Mode: Combined API and database operations via get_adapter(\"fmp\", enable_storage=True)\n\nAll database operations are asynchronous with proper session management, supporting automatic company creation/lookup by ticker and financial data storage with upsert logic in JSONB format.\n</info added on 2025-06-24T14:53:19.470Z>",
            "status": "done"
          },
          {
            "id": 2,
            "title": "Implement Data Type Parsing Logic",
            "description": "Develop parsing routines for each supported data type to convert raw input into structured objects.",
            "dependencies": [
              1
            ],
            "details": "For each data type, write parsing functions that handle transformation from raw data to structured format, referencing best practices for data parsing and transformation.\n<info added on 2025-06-24T14:56:54.763Z>\nImplemented comprehensive data type parsing logic with significant enhancements:\n\n1. Extended Data Models:\n   - Created SEC Filing Models (SECFiling, TenKFiling, TenQFiling) for 10-K/10-Q document parsing\n   - Developed CompanyProfile model for company information parsing\n   - Added support for financial statements (Income Statement, Balance Sheet, Cash Flow), SEC filings, and company profiles\n\n2. Enhanced Parser (EnhancedFMPParser):\n   - Implemented robust error handling with graceful recovery mechanisms\n   - Built comprehensive data transformation pipeline including:\n     * Numeric field cleaning (handling \"null\", \"N/A\", \"-\", string numbers)\n     * Date field normalization to consistent YYYY-MM-DD format\n     * Intelligent default handling for missing fields\n     * Field name normalization for underscore/dash variations\n   - Added support for both single dictionary and list inputs\n   - Developed fuzzy endpoint matching for handling API endpoint variations\n   - Integrated statistics tracking for monitoring parser performance\n\n3. Advanced Parsing Features:\n   - Created intelligent recovery mechanisms for validation failures\n   - Implemented type-specific parsing logic for different document types\n   - Added multi-layer data quality validation with fallback mechanisms\n   - Set up comprehensive logging for debugging and monitoring\n\n4. Testing Infrastructure:\n   - Developed comprehensive test suite with 13 test methods\n   - Added edge case testing for invalid data, missing fields, and format variations\n   - Implemented recovery testing to validate error handling\n   - Created tests for parsing metrics tracking\n\nThe enhanced parser significantly improves data quality and reliability, making the system more resilient to real-world API variations and data inconsistencies.\n</info added on 2025-06-24T14:56:54.763Z>",
            "status": "done"
          },
          {
            "id": 3,
            "title": "Integrate Asynchronous Processing",
            "description": "Enable async processing for data ingestion and parsing to support real-time workflows.",
            "dependencies": [
              2
            ],
            "details": "Refactor parsing and storage logic to use asynchronous patterns (e.g., async/await, promises, or background tasks) to prevent blocking and improve throughput.",
            "status": "done"
          },
          {
            "id": 4,
            "title": "Design and Implement Data Validation",
            "description": "Create validation logic to ensure data integrity and correctness before storage.",
            "dependencies": [
              2
            ],
            "details": "Define validation rules for each data type and implement checks to catch malformed or invalid data prior to storage.",
            "status": "done"
          },
          {
            "id": 5,
            "title": "Develop Storage Logic for Parsed Data",
            "description": "Implement logic to persist validated, parsed data into the backend storage system.",
            "dependencies": [
              3,
              4
            ],
            "details": "Design storage routines that efficiently save data objects, ensuring atomicity and consistency, and handle different data types as required by the backend.",
            "status": "done"
          },
          {
            "id": 6,
            "title": "Implement Robust Error Handling",
            "description": "Add comprehensive error handling throughout the ingestion, parsing, validation, and storage pipeline.",
            "dependencies": [
              3,
              4,
              5
            ],
            "details": "Identify potential failure points, implement try/catch or equivalent mechanisms, and ensure errors are logged and surfaced appropriately for debugging and alerting.",
            "status": "done"
          },
          {
            "id": 7,
            "title": "Conduct End-to-End Testing",
            "description": "Test the complete data ingestion pipeline from adapter input to backend storage, including async flows and error scenarios.",
            "dependencies": [],
            "details": "Develop and execute test cases covering all supported data types, validation failures, async processing, and error handling to ensure system reliability and data integrity.",
            "status": "done"
          }
        ]
      },
      {
        "id": 7,
        "title": "Develop Hard-Coded Prompt Chain for Single Template",
        "description": "Implement a basic LangChain prompt chain for a single sector template.",
        "status": "done",
        "dependencies": [
          2,
          3
        ],
        "priority": "medium",
        "details": "Use LangChain.js v0.3.29 for prompt orchestration. Hard-code prompt logic for the Tech sector template. Required packages: @langchain/core v0.3.61, langchain v0.3.29, @langchain/openai v0.5.16 for GPT-4o-mini integration.",
        "testStrategy": "Test prompt chain execution and output quality with sample financial data. Verify integration with existing types and data structures.",
        "subtasks": [
          {
            "id": 1,
            "title": "LangChain Environment Setup",
            "description": "Install LangChain and its dependencies, configure the development environment, and verify the installation.",
            "status": "done",
            "dependencies": [],
            "details": "This includes installing the LangChain Python package, setting up any required API keys (e.g., for OpenAI), and confirming that basic LangChain imports and example code run successfully.\n<info added on 2025-07-01T11:56:05.083Z>\n## LangChain.js Integration Plan\n\n### Technology Selection\n- Use LangChain.js instead of Python LangChain for direct Next.js integration\n- Benefits: native TypeScript support, runs directly in Next.js API routes, no Python bridge needed, lower latency\n\n### Required Packages\n- @langchain/core v0.3.61\n- langchain v0.3.29\n- @langchain/openai v0.5.16\n- Install using pnpm with workspace protocol\n\n### Implementation Architecture\n- Create new API routes in `apps/web/src/app/api/analysis/`\n- Structure:\n  - `/api/analysis/template/[templateId]/route.ts` - Template-based analysis endpoint\n  - `/api/analysis/score/route.ts` - Scoring endpoint\n\n### Components to Implement\n- Prompt templates for financial metric analysis\n- Chain for orchestrating multiple LLM calls\n- Streaming support for real-time UI updates\n\n### Key Features to Leverage\n- Streaming capabilities for real-time responses\n- TypeScript typing throughout the chain\n- ChatPromptTemplate for structured prompts\n- LCEL (LangChain Expression Language) for chain composition\n\n### Integration Points\n- Connect with existing TanStack Query hooks\n- Use financial data types from `apps/web/src/types/financial.ts`\n- Leverage mock data for initial testing\n- Prepare for future integration with Python scoring module\n</info added on 2025-07-01T11:56:05.083Z>",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Create LangChain Directory Structure and Install Dependencies",
            "description": "Set up the required directory structure for LangChain implementation and install all necessary dependencies.",
            "status": "done",
            "dependencies": [
              1
            ],
            "details": "Create the following directory structure in the web app:\n- `apps/web/src/lib/langchain/chains/` - For chain implementations\n- `apps/web/src/lib/langchain/templates/` - For sector-specific templates\n- `apps/web/src/lib/langchain/utils/` - For utility functions\n\nInstall required packages using pnpm:\n- @langchain/core v0.3.61\n- langchain v0.3.29\n- @langchain/openai v0.5.16\n\nCreate basic index files in each directory to facilitate imports.",
            "testStrategy": "Verify that all directories are created with the correct structure. Confirm that dependencies are properly installed and can be imported in a test file."
          },
          {
            "id": 3,
            "title": "Create Data Transformer Utility",
            "description": "Implement a utility function to transform financial data into the format required by the LangChain prompts.",
            "status": "done",
            "dependencies": [
              2
            ],
            "details": "Create a data transformer utility in `lib/langchain/utils/data-transformer.ts` that converts raw financial data from the FMPFinancialStatements type into a format optimized for prompt templates. Calculate derived metrics like margins, growth rates, and efficiency ratios that are specific to tech sector analysis.",
            "testStrategy": "Test with sample financial data to ensure all required metrics are correctly calculated. Verify that the output format matches what the prompt templates expect."
          },
          {
            "id": 4,
            "title": "Implement Tech Sector Template Configuration",
            "description": "Create a detailed configuration object for the Tech sector template with dimension-specific prompts and weights.",
            "status": "done",
            "dependencies": [
              2
            ],
            "details": "Implement the Tech sector template configuration in `lib/langchain/templates/tech-sector.ts` with:\n- Prompt templates for each dimension (profitability, growth, balance sheet, capital allocation, valuation)\n- Dimension weights (growth: 0.3, profitability: 0.2, balance sheet: 0.2, capital allocation: 0.2, valuation: 0.1)\n- Tech-specific evaluation criteria and benchmarks\n- Proper TypeScript typing for the template configuration",
            "testStrategy": "Verify that all prompt templates are properly formatted and contain the necessary placeholders. Ensure weights sum to 1.0 and the configuration follows the required structure."
          },
          {
            "id": 5,
            "title": "Develop Core Analysis Chain Logic",
            "description": "Implement the core LangChain analysis chain that orchestrates the prompt execution and result processing.",
            "status": "done",
            "dependencies": [
              3,
              4
            ],
            "details": "Create the main analysis chain in `lib/langchain/chains/tech-sector.ts` that:\n- Uses RunnableSequence and RunnableParallel for chain composition\n- Processes each dimension in parallel for efficiency\n- Calculates weighted scores based on template configuration\n- Generates comprehensive insights using a separate prompt\n- Structures the output according to the AnalysisResult type\n- Supports streaming for real-time UI updates",
            "testStrategy": "Test the chain with mock data to verify correct execution flow, proper scoring calculations, and valid output structure. Ensure streaming functionality works as expected."
          },
          {
            "id": 6,
            "title": "Create Output Mapping Utility",
            "description": "Implement a utility function to map LangChain output to the AnalysisResult type.",
            "status": "done",
            "dependencies": [
              5
            ],
            "details": "Create a utility function in `lib/langchain/utils/output-mapper.ts` that:\n- Takes the raw LangChain output and transforms it to match the AnalysisResult interface\n- Ensures all required fields are properly formatted\n- Adds metadata like timestamps and IDs\n- Handles any necessary type conversions or validations",
            "testStrategy": "Test with sample LangChain output to verify correct mapping to the AnalysisResult type. Ensure all required fields are present and properly formatted."
          },
          {
            "id": 7,
            "title": "Implement API Route for Template Analysis",
            "description": "Create the Next.js API route for template-based financial analysis.",
            "status": "done",
            "dependencies": [
              5,
              6
            ],
            "details": "Implement the API route in `app/api/analysis/template/[templateId]/route.ts` that:\n- Accepts financial data and company information as input\n- Validates the template ID (currently only supporting Tech sector template)\n- Initializes the appropriate LangChain model (GPT-4o-mini)\n- Executes the analysis chain with proper error handling\n- Returns a streaming response for real-time UI updates\n- Maps the chain output to the expected AnalysisResult format",
            "testStrategy": "Test the API route with Postman or similar tools to verify correct handling of requests, proper error responses, and valid streaming output format."
          },
          {
            "id": 8,
            "title": "Implement Frontend Integration Hook",
            "description": "Create a TanStack Query hook for integrating the analysis API with the frontend.",
            "status": "done",
            "dependencies": [
              7
            ],
            "details": "Implement a custom hook in `hooks/useCompanyAnalysis.ts` that:\n- Uses TanStack Query for data fetching and caching\n- Handles the streaming response from the analysis API\n- Provides real-time updates to the UI as analysis progresses\n- Properly manages loading, error, and success states\n- Returns the final analysis result in the expected format",
            "testStrategy": "Test the hook in a simple component to verify proper integration with the API, correct handling of streaming data, and appropriate UI state management."
          },
          {
            "id": 9,
            "title": "Create Comprehensive Test Suite",
            "description": "Develop a test suite for the entire prompt chain implementation.",
            "status": "done",
            "dependencies": [
              3,
              4,
              5,
              6,
              7,
              8
            ],
            "details": "Create a comprehensive test suite in `__tests__/langchain/` that tests:\n- Data transformer utility with various financial data inputs\n- Template configuration for correctness and completeness\n- Core analysis chain with mock data and model responses\n- API route with mocked requests and responses\n- Output mapper with various input formats\n- Frontend integration hook with mocked API responses\n- End-to-end flow with mock data",
            "testStrategy": "Use Jest for unit testing and mock the OpenAI API calls to avoid actual API usage during tests. Test both happy paths and error scenarios to ensure robust implementation."
          }
        ]
      },
      {
        "id": 8,
        "title": "Build Scoring Module with Pydantic Validation",
        "description": "Create a module to translate raw metrics into 1100 scores with adjustable weights.",
        "details": "Use Pydantic v2.6 for data validation. Implement scoring logic for Profitability, Growth, Balance-Sheet, Capital Allocation, Valuation. Store weights per template. Recommended: Pydantic v2.6.",
        "testStrategy": "Validate scoring logic with test cases for each dimension and overall score.",
        "priority": "medium",
        "dependencies": [
          2,
          7
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Scoring Logic Design",
            "description": "Develop the core logic for translating input metrics into numerical scores, including handling positive and negative scoring, thresholds, and point decay.",
            "dependencies": [],
            "details": "Define how each metric is scored, assign weights, and ensure the logic supports configurability and validation. Incorporate best practices such as clear criteria, negative scoring, and score thresholds.",
            "status": "done"
          },
          {
            "id": 2,
            "title": "Pydantic Model Creation",
            "description": "Create Pydantic models to validate and structure the input data, scoring configuration, and output scores.",
            "dependencies": [
              1
            ],
            "details": "Design models for input metrics, scoring rules, weights, and output results. Ensure models enforce data types, required fields, and value constraints.",
            "status": "done"
          },
          {
            "id": 3,
            "title": "Weight Configuration",
            "description": "Implement a system for configuring and adjusting the weights assigned to each metric or scoring criterion.",
            "dependencies": [
              2
            ],
            "details": "Allow weights to be set via configuration files or environment variables, and validate them using the Pydantic models. Ensure the system supports easy updates and reflects changes in scoring logic.",
            "status": "done"
          },
          {
            "id": 4,
            "title": "Test Case Development",
            "description": "Develop comprehensive test cases to validate the scoring logic, Pydantic models, and weight configuration.",
            "dependencies": [
              3
            ],
            "details": "Create unit and integration tests covering normal, edge, and invalid cases. Ensure tests verify correct scoring, validation errors, and configurability.",
            "status": "done"
          },
          {
            "id": 5,
            "title": "Integration",
            "description": "Integrate the scoring logic, Pydantic models, and weight configuration into the main application or service.",
            "dependencies": [
              4
            ],
            "details": "Ensure seamless data flow between components, proper error handling, and that the system is ready for end-to-end testing and deployment.",
            "status": "done"
          }
        ]
      },
      {
        "id": 9,
        "title": "Display Scores & Insights in UI",
        "description": "Integrate backend scoring results into the Next.js dashboard, focusing on connecting to real backend endpoints.",
        "status": "pending",
        "dependencies": [
          4,
          5,
          8
        ],
        "priority": "medium",
        "details": "Connect the existing TanStack Query v5 implementation to real FastAPI endpoints. The UI components (ScoreCard, FinancialMetrics) and dashboard pages are already implemented. Focus on backend integration and real-time updates.",
        "testStrategy": "Verify backend integration with real API endpoints, test real-time data updates, and ensure proper error handling with production data.",
        "subtasks": [
          {
            "id": 1,
            "title": "Backend Integration Setup",
            "description": "Connect to real FastAPI endpoints instead of mock APIs, ensuring secure and reliable connections for metric retrieval.",
            "status": "pending",
            "dependencies": [],
            "details": "Update API configuration to point to production/staging FastAPI endpoints. Implement proper authentication and ensure data formats match what the existing UI components expect.",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Data Fetching Updates",
            "description": "Update existing TanStack Query hooks (useCompanies, useCompanyDetails, useScreening, useBulkAnalysisJob) to connect to real backend endpoints.",
            "status": "pending",
            "dependencies": [
              1
            ],
            "details": "Modify the existing hooks to use real API URLs, update any data transformation logic to match real API responses, and ensure caching strategies are appropriate for production use.",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Real-time Updates Implementation",
            "description": "Add WebSocket connections or polling mechanisms to provide real-time data updates for dashboard metrics and analysis results.",
            "status": "pending",
            "dependencies": [
              2
            ],
            "details": "Implement WebSocket client or configure TanStack Query's polling capabilities to refresh data at appropriate intervals. Ensure UI components respond smoothly to data changes.",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Enhanced Error Handling",
            "description": "Improve error handling for real API integration, including graceful fallbacks, user-friendly error messages, and recovery strategies.",
            "status": "pending",
            "dependencies": [
              2
            ],
            "details": "Implement comprehensive error boundaries, create user-friendly error states for each component, and add logging for backend integration issues to aid troubleshooting.",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Integration Testing",
            "description": "Test the integration between frontend components and real backend services, ensuring data flows correctly and UI updates appropriately.",
            "status": "pending",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Create test scenarios that verify end-to-end functionality with real APIs. Test edge cases like slow connections, API errors, and data format changes. Document any issues discovered during testing.",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 10,
        "title": "Add Caching for Repeat Requests",
        "description": "Implement caching for prompt results and scores to reduce latency and API costs. Note: Caching for raw financial data (API responses) is now handled by the data-adapter package.",
        "status": "pending",
        "dependencies": [
          3,
          6
        ],
        "priority": "medium",
        "details": "Use Redis v7 for caching prompt results and generated scores. Key by relevant identifiers (e.g., input hash for prompts, company ID + template ID for scores). Implement freshness checks and appropriate TTLs. Recommended: Redis v7.",
        "testStrategy": "Test cache hit/miss behavior and data freshness validation.",
        "subtasks": [
          {
            "id": 1,
            "title": "Redis Environment Setup",
            "description": "Install and configure Redis, ensuring appropriate tier selection, persistence, and monitoring are enabled for optimal performance.",
            "dependencies": [],
            "details": "Set up Redis on the chosen infrastructure (e.g., Azure, AWS, on-premises). Configure persistence, geo-replication, and monitoring as per best practices.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Cache Key Design",
            "description": "Design a cache key schema that supports prompt results and scores, considering namespace separation and efficient retrieval.",
            "dependencies": [
              1
            ],
            "details": "Define naming conventions and key patterns for prompt results (using input hash) and scores (using company ID + template ID). Ensure keys are unique and support future scalability.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Integration with Data Flows",
            "description": "Integrate Redis caching into application data flows for prompt results and scores, using appropriate caching patterns.",
            "dependencies": [
              2
            ],
            "details": "Modify data access logic to interact with Redis according to the chosen caching strategy. Focus on prompt results and score generation flows, not raw financial data which is now handled by the data-adapter package.",
            "status": "pending"
          },
          {
            "id": 4,
            "title": "Freshness and Expiry Checks",
            "description": "Implement mechanisms to validate cache freshness, including TTL (time-to-live) settings and stale cache handling for prompt results and scores.",
            "dependencies": [
              3
            ],
            "details": "Set appropriate expiration policies for prompt results and scores. Implement logic to check data freshness and reload or invalidate stale entries based on business requirements.",
            "status": "pending"
          },
          {
            "id": 5,
            "title": "Cache Hit/Miss Logic Implementation",
            "description": "Develop logic to handle cache hits and misses for prompt results and scores, ensuring correct fallback to generation services and cache population on misses.",
            "dependencies": [
              4
            ],
            "details": "Implement cache-aside logic: check cache first, handle hits by returning cached data, handle misses by generating new prompt results or scores and updating the cache.",
            "status": "pending"
          },
          {
            "id": 6,
            "title": "Testing and Validation",
            "description": "Test the caching system for correctness, performance, and resilience, including cache hit/miss rates, data consistency, and freshness validation.",
            "dependencies": [
              5
            ],
            "details": "Write and execute tests to verify cache integration, key design, freshness checks, and hit/miss logic. Monitor metrics and adjust configuration as needed.",
            "status": "pending"
          }
        ]
      },
      {
        "id": 11,
        "title": "Develop JSON-Based Template Engine",
        "description": "Enable dynamic loading of templates from JSON definitions.",
        "details": "Store templates in PostgreSQL as JSONB. Load template dynamically per scan. Support 35 pre-loaded sector templates. Recommended: PostgreSQL v15, Pydantic v2.6.",
        "testStrategy": "Validate template loading, prompt chain execution, and scoring with multiple templates.",
        "priority": "medium",
        "dependencies": [
          2,
          7
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "JSON Schema Design",
            "description": "Define the structure, constraints, and data types for the dynamic templates using JSON Schema, including support for nested and modular schemas.",
            "dependencies": [],
            "details": "Create clear and organized JSON schemas that describe the expected data structure for each template. Use best practices such as type hints, required fields, and modular schema composition to enable flexibility and maintainability.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Storage Logic",
            "description": "Design and implement the logic for storing JSON templates and their schemas in a database, supporting both static and dynamic structures.",
            "dependencies": [
              1
            ],
            "details": "Determine how to store templates and schema definitions efficiently, considering whether to use a single JSON column or multiple columns. Optimize for dynamic keys and frequent schema changes as needed.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Dynamic Loading",
            "description": "Implement mechanisms to dynamically load templates and their associated schemas from storage at runtime.",
            "dependencies": [
              2
            ],
            "details": "Ensure that templates and schemas can be retrieved and instantiated on demand, supporting runtime flexibility and minimizing load times.",
            "status": "pending"
          },
          {
            "id": 4,
            "title": "Template Switching",
            "description": "Enable runtime switching between different templates based on user input or application logic.",
            "dependencies": [
              3
            ],
            "details": "Develop logic to allow seamless switching between templates, ensuring that the correct schema and data are loaded and rendered appropriately.",
            "status": "pending"
          },
          {
            "id": 5,
            "title": "Multi-Template Support",
            "description": "Support the coexistence and management of multiple templates, each with its own schema and data.",
            "dependencies": [
              4
            ],
            "details": "Implement features to manage, list, and select among multiple templates, ensuring that each template can be independently validated, loaded, and switched.",
            "status": "pending"
          },
          {
            "id": 6,
            "title": "Validation",
            "description": "Validate data against the appropriate JSON schema for each template, both at input and before storage.",
            "dependencies": [
              1,
              5
            ],
            "details": "Use automated validation tools and best practices to ensure that data conforms to the defined schemas, catching errors early and maintaining data integrity.",
            "status": "pending"
          }
        ]
      },
      {
        "id": 12,
        "title": "Implement Responsive Layout & Filtering",
        "description": "Enhance UI with responsive design and advanced filtering capabilities.",
        "status": "pending",
        "dependencies": [
          4,
          9
        ],
        "priority": "medium",
        "details": "Use Tailwind CSS v3.4 and shadcn/ui v0.7 for responsive components. Add sortable/filterable tables. Recommended: Next.js v14, Tailwind CSS v3.4, shadcn/ui v0.7.",
        "testStrategy": "Test UI responsiveness and filtering on different devices.",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Responsive UI Layouts",
            "description": "Redesign and refactor UI layouts to ensure responsiveness across all screen sizes using flexible layouts, breakpoints, and scalable assets.",
            "status": "completed",
            "dependencies": [],
            "details": "Apply best practices such as flexible layouts with relative units (percentages), define at least three breakpoints (mobile, tablet, desktop), and use SVGs for scalable graphics. Ensure images and containers resize proportionally and navigation adapts to different screens.",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Update and Refactor UI Components",
            "description": "Update existing UI components to ensure they are modular, reusable, and responsive, following card-based and auto-layout principles.",
            "status": "completed",
            "dependencies": [
              1
            ],
            "details": "Refactor components to use card interfaces where appropriate, leverage flexbox or CSS grid for layout efficiency, and ensure buttons and interactive elements are large and tap-friendly. Prioritize essential content and maintain a minimalist approach.",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Implement Advanced Table Features",
            "description": "Enhance table functionality with sorting, column filtering, and search capabilities.",
            "status": "pending",
            "dependencies": [
              2
            ],
            "details": "Build upon the basic table functionality for companies list by adding column sorting (ascending/descending), column-specific filtering options, and a global search feature. Ensure all controls are accessible and responsive across device sizes.",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Optimize Mobile Navigation",
            "description": "Enhance the navigation experience specifically for mobile devices.",
            "status": "pending",
            "dependencies": [
              1
            ],
            "details": "Implement a mobile-friendly navigation pattern (e.g., hamburger menu, bottom navigation bar) that provides easy access to all key sections while maximizing screen space for content. Ensure touch targets are appropriately sized and positioned.",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Implement Responsive Data Visualization",
            "description": "Ensure all charts and graphics adapt appropriately to different screen sizes.",
            "status": "pending",
            "dependencies": [
              1,
              2
            ],
            "details": "Optimize data visualizations to be fully responsive, potentially using different visualization approaches for mobile vs. desktop. Consider simplified views for small screens while maintaining data integrity and readability.",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Develop Advanced Filtering UI Components",
            "description": "Create sophisticated filtering interfaces including dropdowns, date pickers, and multi-select options.",
            "status": "pending",
            "dependencies": [
              2,
              3
            ],
            "details": "Implement advanced filtering UI components that allow users to refine data views. Include date range pickers, multi-select dropdowns, and tag-based filtering. Ensure all filter components are responsive and maintain usability on mobile devices.",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Implement Performance Optimizations",
            "description": "Optimize performance for large datasets using virtual scrolling and other techniques.",
            "status": "pending",
            "dependencies": [
              3,
              6
            ],
            "details": "Implement virtual scrolling or pagination for tables with large datasets to improve performance. Consider lazy loading for images and components that aren't immediately visible. Monitor and optimize render performance across different device capabilities.",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Conduct Cross-Device and Cross-Browser Testing",
            "description": "Test the UI and components on various devices and browsers to ensure consistent appearance and functionality.",
            "status": "pending",
            "dependencies": [
              3,
              4,
              5,
              6,
              7
            ],
            "details": "Perform manual and automated testing across a range of devices (iOS, Android, tablets, desktops) and browsers (Chrome, Firefox, Safari, Edge). Validate that layouts, components, and advanced features work as intended, and address any issues found.",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 13,
        "title": "Integrate Recharts for Data Visualization",
        "description": "Add financial charts and score gauges using Recharts to visualize financial data and analysis scores.",
        "status": "pending",
        "dependencies": [
          4,
          9
        ],
        "priority": "medium",
        "details": "Use Recharts v2.8 to implement various chart types including score gauges/radar charts, line charts for trends, bar charts for comparisons, donut/pie charts for breakdowns, and treemaps for portfolio visualization. Leverage existing data structures in the Next.js frontend for financial statements, analysis scores, historical data, and performance metrics. Integrate with TanStack Query data fetching and ensure TypeScript type safety.",
        "testStrategy": "Validate chart rendering and data accuracy across different chart types. Test responsiveness on mobile and desktop. Verify correct data mapping for financial metrics and scores.",
        "subtasks": [
          {
            "id": 1,
            "title": "Integrate Recharts Library into Project",
            "description": "Install the Recharts library and ensure it is properly added to the React project dependencies.",
            "status": "pending",
            "dependencies": [],
            "details": "Run 'npm install recharts' in the project directory and verify that the package is listed in package.json. Import Recharts components as needed in your codebase.",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Develop Chart Component",
            "description": "Create a reusable chart component using Recharts, following best practices for component structure.",
            "status": "pending",
            "dependencies": [
              1
            ],
            "details": "Implement a chart component (e.g., LineChart, BarChart) in the appropriate directory (such as src/components/charts/). Include necessary Recharts elements like XAxis, YAxis, Tooltip, and Legend.",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Bind Data to Chart Component",
            "description": "Connect the chart component to dynamic data sources and ensure correct data mapping.",
            "status": "pending",
            "dependencies": [
              2
            ],
            "details": "Fetch or receive data (e.g., via props or API call), and pass it to the chart component. Map data fields to chart axes and series as required by Recharts.",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Validate Chart Rendering and Data Accuracy",
            "description": "Test the chart component to confirm it renders correctly and accurately reflects the bound data.",
            "status": "pending",
            "dependencies": [
              3
            ],
            "details": "Visually inspect the chart in the application, verify that all chart elements display as expected, and confirm that the data shown matches the source data. Address any rendering or data binding issues.",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Implement Score Gauges/Radar Charts",
            "description": "Create visualizations for analysis scores by dimension (profitability, growth, balance sheet, capital allocation, valuation).",
            "status": "pending",
            "dependencies": [
              2
            ],
            "details": "Use Recharts RadarChart or create custom gauge components to display MetricScores. Ensure proper color coding based on score values. Integrate with the existing ScoreCard component.",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Develop Financial Trend Line Charts",
            "description": "Implement line charts to visualize financial metrics over time.",
            "status": "pending",
            "dependencies": [
              2
            ],
            "details": "Create line charts that display historical financial data across multiple periods (Q1, Q2, Q3, Q4). Include proper tooltips, legends, and responsive configurations. Integrate with the FinancialMetrics component.",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Create Quarterly Comparison Bar Charts",
            "description": "Build bar charts for comparing financial metrics across quarters.",
            "status": "pending",
            "dependencies": [
              2
            ],
            "details": "Implement bar charts that allow users to compare key financial metrics across different quarters. Include proper labeling, tooltips, and color coding.",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Implement Financial Breakdown Donut/Pie Charts",
            "description": "Create donut or pie charts to visualize financial breakdowns.",
            "status": "pending",
            "dependencies": [
              2
            ],
            "details": "Use Recharts PieChart to display financial breakdowns such as revenue sources, expense categories, or other proportional financial data. Include proper legends and interactive elements.",
            "testStrategy": ""
          },
          {
            "id": 9,
            "title": "Develop Portfolio Treemap Visualization",
            "description": "Implement a treemap chart for portfolio visualization.",
            "status": "pending",
            "dependencies": [
              2
            ],
            "details": "Create a treemap using Recharts to visualize portfolio allocation or other hierarchical financial data. Configure proper sizing, coloring, and tooltips for effective data representation.",
            "testStrategy": ""
          },
          {
            "id": 10,
            "title": "Create Dedicated ChartsSection Component",
            "description": "Develop a dedicated section for the dashboard to showcase various financial charts.",
            "status": "pending",
            "dependencies": [
              5,
              6,
              7,
              8,
              9
            ],
            "details": "Create a ChartsSection component that organizes and displays the various chart types in a cohesive layout. Implement tabs or other navigation elements to allow users to switch between different chart views.",
            "testStrategy": ""
          },
          {
            "id": 11,
            "title": "Implement Responsive Chart Configurations",
            "description": "Ensure all charts are responsive and display properly on both mobile and desktop devices.",
            "status": "pending",
            "dependencies": [
              5,
              6,
              7,
              8,
              9
            ],
            "details": "Configure charts to adapt to different screen sizes. Implement responsive width/height calculations, adjust font sizes and spacing, and possibly create alternative layouts for mobile views.",
            "testStrategy": ""
          },
          {
            "id": 12,
            "title": "Integrate with TanStack Query and TypeScript",
            "description": "Ensure proper integration with existing data fetching mechanisms and type safety.",
            "status": "pending",
            "dependencies": [
              3
            ],
            "details": "Leverage the existing TanStack Query setup for data fetching. Create appropriate TypeScript interfaces for chart data and props. Ensure type safety throughout the chart components and data mapping functions.",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 14,
        "title": "Enable Report Export to PDF/CSV",
        "description": "Add functionality to export analysis results to PDF and CSV.",
        "status": "pending",
        "dependencies": [
          9,
          12
        ],
        "priority": "medium",
        "details": "Use pdf-lib v1.17 for PDF generation, csv-writer v6.0 for CSV. Integrate with existing Next.js frontend that already has UI components and data structures ready for export functionality. Focus on backend implementation and seamless frontend integration.",
        "testStrategy": "Test export functionality and file content accuracy. Verify all exportable data types (company analysis, financial statements, recommendations, company lists) render correctly in both formats.",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement PDF Export Logic",
            "description": "Develop backend logic to export data into PDF format, ensuring correct formatting and data integrity.",
            "status": "pending",
            "dependencies": [],
            "details": "Use pdf-lib v1.17 to convert data into a well-structured PDF document. Support all exportable data types: company analysis results, financial statements, recommendations, and company lists. Ensure headers, tables, and content are accurately represented.",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement CSV Export Logic",
            "description": "Develop backend logic to export data into CSV format, handling headers, delimiters, and data encoding.",
            "status": "pending",
            "dependencies": [],
            "details": "Use csv-writer v6.0 to iterate over data rows and columns, outputting them as CSV with appropriate separators and handling edge cases like null values or special characters. Support all exportable data types that are already structured in TypeScript interfaces.",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Integrate Export Options into UI",
            "description": "Add export buttons and options to the user interface, allowing users to trigger PDF or CSV exports.",
            "status": "pending",
            "dependencies": [
              1,
              2
            ],
            "details": "Integrate with existing Next.js frontend components at specified integration points: company detail pages, companies table toolbar, and dashboard for bulk exports. Implement format selection UI (PDF vs CSV options).",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Handle File Download in Frontend",
            "description": "Implement logic to handle file downloads in the browser after export is triggered from the UI.",
            "status": "pending",
            "dependencies": [
              3
            ],
            "details": "Use browser APIs (File API, URL.createObjectURL) to handle downloads. Implement progress indicators for large export jobs. Ensure files download automatically with meaningful filenames and correct MIME types. Implement error handling for export failures.",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Validate Export Functionality",
            "description": "Test and validate that exported files (PDF and CSV) contain correct data, proper formatting, and are downloadable from the UI.",
            "status": "pending",
            "dependencies": [
              4
            ],
            "details": "Perform manual and automated tests to verify data accuracy, file integrity, and user experience for both export formats. Test all integration points (company detail pages, table toolbar, dashboard) and all exportable data types (analysis results, financial statements, recommendations, company lists).",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Implement Bulk Export Functionality",
            "description": "Add capability to export multiple companies or reports simultaneously from the dashboard.",
            "status": "pending",
            "dependencies": [
              1,
              2
            ],
            "details": "Develop backend logic to handle bulk export requests, potentially using background processing for large exports. Ensure proper progress indication and notification when exports are complete.",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 15,
        "title": "Implement Bulk Screening Workflow",
        "description": "Enable processing of 11,000+ tickers in parallel with progress tracking.",
        "status": "pending",
        "dependencies": [
          2,
          6,
          11
        ],
        "priority": "medium",
        "details": "Use Celery v5.3 or AWS Lambda for task queue. Stream results to UI with progress bars. Leverage existing Next.js frontend components and hooks for bulk analysis job handling.",
        "testStrategy": "Test bulk processing, progress updates, and result accuracy. Ensure compatibility with existing frontend API contract.",
        "subtasks": [
          {
            "id": 1,
            "title": "Task Queue Setup",
            "description": "Design and implement a robust task queue system to manage incoming work units and distribute them to worker processes.",
            "status": "pending",
            "dependencies": [],
            "details": "Select a queue technology (Celery/Redis or AWS Lambda as specified), define the task schema compatible with existing BulkAnalysisJob interface, and ensure thread/process safety for concurrent access.",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Parallel Processing Logic",
            "description": "Develop logic for parallel task execution using a pool of worker processes or threads that fetch and process tasks from the queue.",
            "status": "pending",
            "dependencies": [
              1
            ],
            "details": "Implement worker pool management, task fetching, and execution logic. Ensure efficient resource utilization and avoid race conditions. Support processing of 1-1,000+ tickers simultaneously.",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Progress Tracking",
            "description": "Implement mechanisms to track the progress of each task and overall job status in real time.",
            "status": "pending",
            "dependencies": [
              2
            ],
            "details": "Implement backend progress tracking compatible with the existing frontend data structure (status: PENDING/IN_PROGRESS/COMPLETED/FAILED, progress: 0.0-1.0). Ensure compatibility with the useBulkAnalysisJob hook.",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Result Streaming",
            "description": "Enable streaming of task results to the UI or client as soon as they are available, rather than waiting for all tasks to complete.",
            "status": "pending",
            "dependencies": [
              3
            ],
            "details": "Implement WebSocket connections for real-time updates. Ensure compatibility with existing TanStack Query implementation in the frontend for result streaming.",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Error Handling",
            "description": "Design and implement comprehensive error handling for failed tasks, including retries, logging, and user notifications.",
            "status": "pending",
            "dependencies": [
              2
            ],
            "details": "Define error categories, implement retry logic, and ensure errors are surfaced to progress tracking and result streaming systems. Align with frontend error handling mechanisms.",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Scaling Tests",
            "description": "Conduct scalability and performance tests to ensure the system can handle high task volumes and parallelism efficiently.",
            "status": "pending",
            "dependencies": [
              2,
              5
            ],
            "details": "Simulate large workloads (up to 1,000+ tickers), monitor resource usage, and identify bottlenecks or failure points under load.",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Backend API Implementation",
            "description": "Implement the backend API endpoints to match the existing frontend contract.",
            "status": "pending",
            "dependencies": [
              3,
              4,
              5
            ],
            "details": "Implement GET/POST /api/analysis/bulk endpoints to match the existing mock API contract. Ensure proper integration with the task queue and progress tracking systems.",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Job Persistence and Recovery",
            "description": "Implement mechanisms for job persistence and recovery in case of system failures.",
            "status": "pending",
            "dependencies": [
              1,
              2
            ],
            "details": "Design and implement a storage solution for job state that allows recovery after crashes or restarts. Ensure jobs can be resumed from their last known state.",
            "testStrategy": ""
          },
          {
            "id": 9,
            "title": "WebSocket Server Implementation",
            "description": "Set up WebSocket server for real-time progress and result updates.",
            "status": "pending",
            "dependencies": [
              3,
              4
            ],
            "details": "Implement WebSocket server that can push updates to connected clients. Ensure proper authentication, connection management, and message formatting compatible with the frontend expectations.",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 16,
        "title": "Add Auth & Multi-Tenant Support",
        "description": "Implement email/social sign-in, workspace separation, and team roles.",
        "status": "pending",
        "dependencies": [
          2,
          5
        ],
        "priority": "medium",
        "details": "Use Supabase Auth or Auth0. Enforce tenancy at API gateway. Leverage existing Next.js frontend integration points for authentication and multi-tenancy features, including layout components, API hooks, middleware for route protection, and workspace context throughout the app.",
        "testStrategy": "Test user authentication, workspace isolation, role-based access, and Next.js-specific integration points including middleware, server-side authentication, client-side auth state management, and API route authentication middleware.",
        "subtasks": [
          {
            "id": 1,
            "title": "Integrate Authentication Provider",
            "description": "Implement a secure and standards-based authentication provider integration using OAuth2 and OpenID Connect for single sign-on (SSO), leveraging trusted third-party providers like Google or Microsoft Azure to avoid managing passwords internally.",
            "status": "pending",
            "dependencies": [],
            "details": "Use OAuth2 framework for token exchange and SSO to reduce user friction and improve security by offloading authentication to trusted providers. Follow best practices such as using HTTPS/TLS, secure token storage, and leveraging existing libraries to minimize custom implementation effort.",
            "testStrategy": "Verify successful authentication flows with selected providers, token validation, and secure storage of authentication state."
          },
          {
            "id": 2,
            "title": "Implement Workspace Separation Logic",
            "description": "Design and implement multi-tenancy logic to separate data and access by workspace or tenant, ensuring isolation and security between different customer environments.",
            "status": "pending",
            "dependencies": [
              1
            ],
            "details": "Define workspace boundaries in the data model and enforce access controls at the API and database layers to prevent cross-tenant data leakage. Use tenant identifiers in authentication tokens and API requests to scope data access appropriately.",
            "testStrategy": "Test workspace isolation by verifying data access is properly scoped to the current workspace and that cross-workspace access is prevented."
          },
          {
            "id": 3,
            "title": "Develop Role Management System",
            "description": "Create a role-based access control (RBAC) system to manage user permissions within each workspace, assigning roles that grant the minimum necessary privileges.",
            "status": "pending",
            "dependencies": [
              2
            ],
            "details": "Implement roles and permissions aligned with the principle of least privilege. Integrate role assignments with authentication tokens and enforce role checks in API endpoints to control user actions based on their assigned roles.",
            "testStrategy": "Verify that users can only perform actions allowed by their assigned roles and that role changes are immediately reflected in access permissions."
          },
          {
            "id": 4,
            "title": "Enforce API Security and Access Controls",
            "description": "Apply authentication and authorization enforcement on all API endpoints, including validation of tokens, workspace scoping, and role-based permissions.",
            "status": "pending",
            "dependencies": [
              3
            ],
            "details": "Use HTTPS/TLS for all API communications. Validate JWT or OAuth tokens on each request, check workspace identifiers, and verify user roles before granting access. Implement rate limiting, input validation, and logging for security and auditing purposes.",
            "testStrategy": "Test API security by attempting unauthorized access, cross-workspace requests, and actions beyond role permissions to ensure proper enforcement."
          },
          {
            "id": 5,
            "title": "Update User Interface for Authentication and Authorization",
            "description": "Modify the UI to support authentication flows, workspace selection, and role-based access controls, providing users with appropriate views and actions based on their permissions.",
            "status": "pending",
            "dependencies": [
              4
            ],
            "details": "Integrate login/logout flows using the chosen authentication provider. Display workspace context and allow users to switch workspaces if permitted. Show or hide UI elements based on user roles to prevent unauthorized actions.",
            "testStrategy": "Verify that UI elements correctly reflect authentication state, workspace context, and user roles, with appropriate elements hidden or disabled based on permissions."
          },
          {
            "id": 6,
            "title": "Conduct Security Testing and Audits",
            "description": "Perform comprehensive security testing including penetration tests, vulnerability scans, and audits to ensure the authentication, workspace separation, role management, and API enforcement are secure and robust.",
            "status": "pending",
            "dependencies": [
              4,
              5
            ],
            "details": "Test for common vulnerabilities such as injection attacks, improper access controls, token misuse, and data leakage between workspaces. Verify compliance with security best practices and document findings for remediation.",
            "testStrategy": "Conduct penetration testing, vulnerability scanning, and security audits to identify and address potential security issues."
          },
          {
            "id": 7,
            "title": "Implement Next.js-Specific Authentication Integration",
            "description": "Leverage Next.js features for authentication and authorization, including middleware for route protection and server-side authentication.",
            "status": "pending",
            "dependencies": [
              1
            ],
            "details": "Implement Next.js middleware for route protection, set up server-side authentication with getServerSideProps where needed, and create client-side auth state management using context providers. Ensure authentication state persists across page refreshes and implement automatic token refresh handling.",
            "testStrategy": "Test route protection, server-side authentication, client-side auth state management, and token refresh functionality across different page navigation scenarios."
          },
          {
            "id": 8,
            "title": "Integrate Auth with TanStack Query and API Hooks",
            "description": "Enhance existing API hooks to include authentication headers and workspace context for all data fetching operations.",
            "status": "pending",
            "dependencies": [
              1,
              2,
              7
            ],
            "details": "Modify TanStack Query hooks to automatically include authentication tokens and workspace identifiers in API requests. Implement error handling for authentication failures and token refresh scenarios.",
            "testStrategy": "Verify that API requests include proper authentication headers and workspace context, and that authentication failures are properly handled."
          },
          {
            "id": 9,
            "title": "Develop Workspace Switching UI in Navigation",
            "description": "Create a user interface component for workspace selection and switching within the application navigation.",
            "status": "pending",
            "dependencies": [
              2,
              5
            ],
            "details": "Implement a dropdown or similar UI element in the navigation bar that displays the current workspace and allows users to switch between workspaces they have access to. Ensure the workspace context is updated throughout the application when switched.",
            "testStrategy": "Test workspace switching functionality, verifying that the UI updates correctly and that data access is properly scoped to the newly selected workspace."
          },
          {
            "id": 10,
            "title": "Implement Component-Level Role-Based Visibility Controls",
            "description": "Create a system for conditionally rendering UI components based on user roles and permissions.",
            "status": "pending",
            "dependencies": [
              3,
              5,
              7
            ],
            "details": "Develop higher-order components or hooks that can wrap UI elements to conditionally render them based on the user's role and permissions. Integrate with the authentication context to access role information.",
            "testStrategy": "Test component visibility controls by verifying that UI elements are correctly shown or hidden based on user roles and permissions."
          },
          {
            "id": 11,
            "title": "Implement Auth State Persistence and Token Refresh",
            "description": "Ensure authentication state persists across page refreshes and implement automatic token refresh handling.",
            "status": "pending",
            "dependencies": [
              1,
              7
            ],
            "details": "Use secure storage mechanisms for persisting authentication state. Implement token refresh logic to handle expiring tokens without disrupting the user experience. Ensure all components react appropriately to auth state changes.",
            "testStrategy": "Test auth state persistence across page refreshes and browser sessions. Verify automatic token refresh works correctly when tokens approach expiration."
          },
          {
            "id": 12,
            "title": "Create API Route Authentication Middleware",
            "description": "Develop middleware for Next.js API routes to enforce authentication and authorization checks.",
            "status": "pending",
            "dependencies": [
              1,
              4,
              7
            ],
            "details": "Create reusable middleware for Next.js API routes that validates authentication tokens, checks workspace context, and enforces role-based permissions before allowing access to API functionality.",
            "testStrategy": "Test API route middleware by attempting various authenticated and unauthenticated requests with different roles and workspace contexts."
          },
          {
            "id": 13,
            "title": "Integrate Login/Logout Pages with Existing Layout",
            "description": "Implement authentication UI pages that integrate seamlessly with the existing application layout.",
            "status": "pending",
            "dependencies": [
              1,
              5
            ],
            "details": "Create login, logout, and related authentication pages that maintain consistent branding and UX with the rest of the application. Ensure smooth transitions between authenticated and unauthenticated states.",
            "testStrategy": "Test authentication UI for usability, visual consistency, and proper integration with the existing application layout and navigation flow."
          }
        ]
      },
      {
        "id": 17,
        "title": "Implement Embeddings Store with pgvector",
        "description": "Implement an embeddings store using pgvector for AI-generated content and user queries to reduce latency and costs. This task focuses exclusively on storing embeddings for AI outputs, not raw financial data which is now handled by the data-adapter package.",
        "status": "pending",
        "dependencies": [
          2,
          10
        ],
        "priority": "low",
        "details": "Use PostgreSQL with the pgvector extension to store and retrieve embeddings for AI-generated text (analysis summaries, insights) and user queries. Key embeddings by a hash of the content that was embedded. Implement freshness checks to re-generate embeddings if the source text changes. Recommended: PostgreSQL v15, pgvector v0.6.",
        "testStrategy": "Test embedding storage, retrieval, and freshness validation for AI-generated content and user queries.",
        "subtasks": [
          {
            "id": 1,
            "title": "pgvector Setup",
            "description": "Install and configure the pgvector extension in PostgreSQL. Ensure the database is running with pgvector enabled and verify the extension is active.",
            "status": "pending",
            "dependencies": [],
            "details": "Follow installation steps for pgvector, either via package manager or Docker. Run `CREATE EXTENSION IF NOT EXISTS vector;` in the database to enable pgvector. Confirm the extension is installed and operational.",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Embedding Storage Logic",
            "description": "Design and implement the database schema for storing embeddings of AI-generated content and user queries. Develop logic to insert and update vector embeddings in the database.",
            "status": "pending",
            "dependencies": [
              1
            ],
            "details": "Create tables with a vector column (e.g., `embedding vector(1536)`). Implement application logic to store and update embeddings, ensuring compatibility with pgvector's data types. Use content hash as the primary key. Create separate tables for AI-generated content embeddings and user query embeddings.",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Retrieval API",
            "description": "Develop an API endpoint for retrieving embeddings using vector similarity search. Support nearest neighbor queries for finding similar AI-generated content or past user queries.",
            "status": "pending",
            "dependencies": [
              2
            ],
            "details": "Implement API logic to query the database using pgvector's similarity operators (e.g., `<->` for Euclidean distance). Ensure the API can handle query parameters for similarity search across AI-generated content and previous user queries.",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Freshness Checks",
            "description": "Implement mechanisms to ensure AI-generated content embeddings are up-to-date. Add logic to check and refresh embeddings when source text changes.",
            "status": "pending",
            "dependencies": [
              2
            ],
            "details": "Track timestamps and content hashes for embeddings. Add logic to verify embedding freshness before retrieval, and trigger re-embedding if the source AI-generated content has changed.",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Integration Testing",
            "description": "Develop and execute integration tests covering embedding storage, retrieval, and freshness logic for AI-generated content and user queries. Validate end-to-end functionality and performance.",
            "status": "pending",
            "dependencies": [
              3,
              4
            ],
            "details": "Write tests that insert, update, and retrieve embeddings via the API. Test freshness checks and ensure correct results are returned. Measure performance and correctness for both AI-generated content and user query scenarios.",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Clear Separation from data-adapter",
            "description": "Ensure clear separation between this embeddings store and the data-adapter package's caching functionality.",
            "status": "pending",
            "dependencies": [
              2
            ],
            "details": "Document the distinct responsibilities: data-adapter handles raw financial filing caching, while this embeddings store focuses exclusively on AI-generated content and user queries. Ensure no overlap in functionality or data storage.",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "User Query Embedding Storage",
            "description": "Implement specialized storage for user query embeddings to enable finding similar past queries.",
            "status": "pending",
            "dependencies": [
              2
            ],
            "details": "Create a dedicated table structure for storing user query embeddings with appropriate metadata (timestamp, user context, etc.). Implement logic to store new query embeddings and find similar past queries.",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 18,
        "title": "Deploy Microservices with Kubernetes/ECS",
        "description": "Containerize services and deploy to Kubernetes or AWS ECS for scalability.",
        "details": "Use Docker v24 for containerization. Deploy to Kubernetes v1.28 or AWS ECS. Recommended: Docker v24, Kubernetes v1.28.",
        "testStrategy": "Validate container deployment, service discovery, and scaling.",
        "priority": "medium",
        "dependencies": [
          1,
          5
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Containerization of Microservices",
            "description": "Package each microservice into its own container, ensuring statelessness and immutability for portability and scalability.",
            "dependencies": [],
            "details": "Follow best practices such as one application per container, keeping containers stateless and immutable, and optimizing image size for efficient deployment and scaling.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Service Definition",
            "description": "Define clear service boundaries and interfaces for each microservice, including API contracts and dependencies.",
            "dependencies": [
              1
            ],
            "details": "Utilize domain-driven design to identify natural service boundaries and ensure each service is cohesive and loosely coupled. Document APIs and expected behaviors.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Deployment Script Creation",
            "description": "Develop scripts to automate the deployment of containerized services to the target environment.",
            "dependencies": [
              1,
              2
            ],
            "details": "Write scripts (e.g., Docker Compose, Helm charts, or Kubernetes manifests) to build, push, and deploy containers, ensuring repeatability and consistency across environments.",
            "status": "pending"
          },
          {
            "id": 4,
            "title": "Cluster Setup",
            "description": "Provision and configure the orchestration cluster (e.g., Kubernetes, Docker Swarm) for running the containerized microservices.",
            "dependencies": [
              3
            ],
            "details": "Set up the cluster infrastructure, configure networking, storage, and security policies, and ensure the environment is ready for service deployment.",
            "status": "pending"
          },
          {
            "id": 5,
            "title": "Service Discovery Configuration",
            "description": "Implement service discovery mechanisms to enable dynamic location and communication between microservices.",
            "dependencies": [
              4
            ],
            "details": "Configure built-in service discovery features of the orchestration platform or integrate third-party solutions to allow services to find and communicate with each other reliably.",
            "status": "pending"
          },
          {
            "id": 6,
            "title": "Scaling Configuration",
            "description": "Set up scaling policies and configurations to ensure services can scale horizontally based on demand.",
            "dependencies": [
              5
            ],
            "details": "Define resource requests/limits, configure auto-scaling rules, and test scaling behavior to maintain performance and availability under varying loads.",
            "status": "pending"
          },
          {
            "id": 7,
            "title": "Deployment Validation",
            "description": "Validate the deployment by testing service functionality, connectivity, and scaling under real-world scenarios.",
            "dependencies": [],
            "details": "Perform smoke tests, integration tests, and load tests to ensure all services are running as expected, can discover each other, and scale appropriately.",
            "status": "pending"
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-06-19T14:40:29.469Z",
      "updated": "2025-07-02T17:25:13.049Z",
      "description": "Tasks for master context"
    }
  }
}